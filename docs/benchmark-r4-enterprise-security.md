# MemoryForge — Enterprise Security Benchmark (Round 4)

PERSONA: Enterprise Security Engineer (15% of market)
VERDICT: Conditional — Impressive zero-dependency posture and solid path-traversal guards, but shell-hook injection vectors, missing input sanitization on several MCP tool fields, and no cryptographic integrity checks on config/state files need remediation before org-wide deployment.

SCORES:
D1 Supply Chain: 9 — Zero runtime dependencies (no package.json, no node_modules), pure Node.js stdlib only; the only external actions in CI are actions/checkout@v4 and actions/setup-node@v4, both pinned to major versions but not to SHA digests.
D2 Input Validation: 5 — 50KB global input cap and required-field checks exist, but individual string fields (phase, status, title, decision, task, summary) have no type coercion, length bounds, or character-class restrictions; user-supplied content is interpolated directly into Markdown without escaping, and the extractSection regex uses unescaped user-sourced heading names enabling potential ReDoS on STATE.md heading extraction.
D3 Path Safety: 8 — safePath() using path.resolve + startsWith check is correctly implemented for the MCP server; however, shell hooks reference CLAUDE_PROJECT_DIR directly in file paths without sanitizing for shell metacharacters, and the compress-sessions.js mindDir CLI argument is used as-is from argv without validation.
D4 Data Handling: 7 — All data stays local in .mind/ with no network egress; .gitignore template excludes tracking/error files; however, there is no project-level isolation guarantee when the MCP server walks up 10 parent directories looking for .mind/, which could cause cross-project state leakage if a parent directory has a .mind/ folder; the archive and backup files (.pre-compress) are not access-controlled.
D5 Configuration Security: 6 — Config is loaded via JSON.parse (no eval/require), and numeric values are bounds-clamped; however, shell hooks interpolate config values directly into arithmetic expressions (e.g., COMPRESS_THRESHOLD and STALE_SECONDS) without validating they are numeric, and the config file path is derived from the mindDir parent without canonicalization, making it susceptible to symlink-based config substitution.
D6 CI/CD Integration: 7 — CI matrix covers 3 OSes x 3 Node versions with shellcheck linting and JSON template validation; however, hook tests are not run in CI (only MCP server, compression, and vector tests), there is no SAST/DAST/dependency scanning step, and the CI actions are not pinned to SHA digests.
D7 Audit Trail: 6 — Error logging to .mcp-errors.log with timestamps covers MCP server errors, uncaught exceptions, and unhandled rejections; session-tracking file records session end reasons; however, there is no structured audit log for successful tool invocations (who called what, when), no log rotation beyond the 100KB tail-truncation in session-start, and hook execution outcomes are not logged anywhere persistent.

AVERAGE: 6.86

STRENGTHS:
- Genuinely zero dependencies: no package.json, no node_modules, no lock files. This eliminates the entire npm supply chain attack surface, which is rare and commendable for a Node.js project.
- Path traversal protection (safePath) is correctly implemented using path.resolve and startsWith comparison, with a dedicated test covering traversal payloads. This is the single most important security control and it works.
- MCP transport layer handles multi-byte characters correctly using raw Buffers for Content-Length framing, with a 10MB message cap preventing OOM. The explicit test for Unicode framing demonstrates awareness of this attack class.
- Configuration is JSON-only (JSON.parse), not require(). Config values are bounds-clamped with Math.max/Math.floor. No eval, no dynamic code execution from config.
- Clean uninstall with --dry-run preview, smart merge that preserves existing settings, and backup creation before destructive operations show mature operational design.

GAPS:
- Shell injection in hooks: CLAUDE_PROJECT_DIR is used unquoted or interpolated into Node -e strings in several hooks (session-start.sh line 50: `'$PROJECT_DIR/.memoryforge.config.json'` inside a Node -e heredoc, stop-checkpoint.sh line 77 similarly). A malicious project directory name containing single quotes or backticks could escape the Node -e string and achieve arbitrary code execution. This is the most critical finding.
- No per-tool input sanitization: MCP tool arguments for string fields like `phase`, `title`, `decision`, `rationale`, `summary` are written verbatim to Markdown files. While there is no direct code execution risk, an attacker controlling tool input could inject Markdown that misleads the AI (prompt injection via state poisoning). The 50KB cap is a blunt instrument; per-field length limits and character restrictions are absent.
- Cross-project .mind/ resolution: findMindDir() walks up 10 parent directories. In a monorepo or nested project structure, this could resolve to an ancestor project's .mind/ directory, causing unintended cross-project state reads and writes. There is no project identity verification (e.g., comparing against a project hash).
- No integrity verification on .mind/ files: There is no checksum or HMAC on state files. A local attacker (or another tool) could modify STATE.md, DECISIONS.md, or PROGRESS.md between sessions, and MemoryForge would trust the contents unconditionally. For enterprise use, tamper detection on state files would be valuable.
- Hook tests are not in the CI pipeline: The ci.yml runs mcp-server.test.js, compress.test.js, and vector-memory.test.js, but hooks.test.js is conspicuously absent. Hook scripts are the primary attack surface (shell execution), and not testing them in CI is a gap.

BUGS:
- [P1] Shell injection via CLAUDE_PROJECT_DIR in hook scripts — In session-start.sh (line 50), stop-checkpoint.sh (line 77), and other hooks, the PROJECT_DIR variable is interpolated inside single-quoted Node -e strings using shell expansion (`'$PROJECT_DIR/.memoryforge.config.json'`). If CLAUDE_PROJECT_DIR contains a single quote, the Node -e string is broken, enabling arbitrary command execution. Example: a project path of `/tmp/foo';require('child_process').execSync('id');//` would escape the string. Remediation: pass the path as a Node process.argv argument (as done correctly in session-start.sh line 228) rather than interpolating into -e strings.
- [P2] extractSection() ReDoS potential — In mcp-memory-server.js line 381, `extractSection(content, heading)` builds a regex from the `heading` parameter without escaping regex metacharacters. While the heading is typically a hardcoded string like "Current Phase", the function is exported-style and could be called with user-controlled headings if STATE.md contains crafted section names with regex-active characters. The memorySaveProgress function (line 334) correctly escapes its regex input, but extractSection does not.
- [P2] TOCTOU race in compress-sessions.js — Between reading file content (readFile at line 56), checking size, and writing the compressed output (writeFileSync at line 162), another process could modify the file. The backup is created with copyFileSync, but if the file changes between the read and the copy, the backup will contain different content than what was compressed. For a single-user CLI tool this is low-severity, but for enterprise environments with concurrent CI agents it could cause data loss.
- [P3] Unbounded checkpoint file creation — pre-compact.sh creates timestamped checkpoint files (line 94) and prunes to keep 10, but if compaction fires rapidly (e.g., a tight loop in a malfunctioning client), many files could be created between prune cycles. The prune only runs within the same invocation, not as a separate cleanup. This is a minor disk exhaustion vector.
- [P3] Missing input type validation on MCP tool arrays — memory_update_state accepts `active_work` and `blockers` as arrays, but if a non-array, non-string value is passed (e.g., a number or nested object), String() coercion at line 195 could produce unexpected results like "[object Object]" written to STATE.md. The inputSchema declares the type but the server does not enforce it beyond checking for required fields.
